{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14강_ Keras 예제(FA, GAN)",
      "provenance": [],
      "authorship_tag": "ABX9TyNsL1DK6fRKhl1lpyPJJ7/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsmsm/ASL/blob/master/14%EA%B0%95__Keras_%EC%98%88%EC%A0%9C(FA%2C_GAN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TibNGSDQgRA"
      },
      "source": [
        "#요인 분석 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qTADediQl3u"
      },
      "source": [
        "###MNIST 모듈 및 요인 분석 함수 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv0GwOwVQm51"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.decomposition import FactorAnalysis as FA"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2IV1VMnQq1B"
      },
      "source": [
        "###MNIST 자료를 불러오고 형태 변환 (28,28) → (28*28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSgIwIOMQtYT"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 28*28) \n",
        "X_test = X_test.reshape(X_test.shape[0], 28*28) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGlafEB_Qwlw"
      },
      "source": [
        "###훈련자료를 이용해 잠재 요인 찾기(n_components는 찾을 잠재 요인의 개수)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyziQQufQz_Z"
      },
      "source": [
        "fa = FA(n_components = 10, random_state = 77)\n",
        "fa.fit(X_train)\n",
        "\n",
        "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10, noise_variance_init=None, random_state=77, svd_method=’randomized’, tol=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "699Zz4YBQ6Xj"
      },
      "source": [
        "###램덤하게 공통 인자 벡터를 생성한 뒤 그것과 추정값을 바탕으로 원래와 비슷한 꼴의 자료를생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R82B6A3dQ7Xx"
      },
      "source": [
        "np.random.seed(15)\n",
        "loading = np.transpose(fa.components)\n",
        "generated = np.transpose(np.dot(loading, np.random.normal(size=(10,10)))\n",
        "mu = np.mean(X_train,0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,3)\n",
        "\n",
        "for i in range(10)\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.axis(‘off’)\n",
        "    plt.imshow(mu+generated[i] . reshape(28,28), cmap=’gray’)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zXCNbYcQ_up"
      },
      "source": [
        "#DCGAN 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DYKrl1YRCel"
      },
      "source": [
        "###input noise의 차원 : 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpbkgTS8RM_0"
      },
      "source": [
        "randomDim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoriS0KRRN26"
      },
      "source": [
        "###MNIST 자료 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQHv2p1RQxS"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) – 127.5)/127.5 \n",
        "X_test = X_test[:, np.newaxis. :, :] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4ZGL4-dRVQp"
      },
      "source": [
        "###최적화 알고리즘은 ADAM 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlnwYjRPRYD6"
      },
      "source": [
        "adam = Adam(lr=0.0002, beta_1=0.5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enKwApzLRa9P"
      },
      "source": [
        "###생성함수 구조 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlX7lmFWReWU"
      },
      "source": [
        "generator = Sequential()\n",
        "generator.add(Dense(128*7*7,input_dim=randomDim,kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "generator.add(LeakyRelu(0.2))\n",
        "generator.add(Reshape((128, 7, 7)))\n",
        "generator.add(UpSampling20(size=(2, 2)))\n",
        "generator.add(Conv2D(64, kernel_size=(5, 5), padding=’same’))\n",
        "generator.add(LeakyRelu(0.2))\n",
        "generator.add(UpSampling20(size=(2, 2)))\n",
        "generator.add(Conv2D(64, kernel_size=(5, 5), padding=’same’, activation=’tanh’))\n",
        "generator.compile(loss=’binary_crossentropy’, optimizer=adam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13blw2ziRgvU"
      },
      "source": [
        "### 판별함수 구조 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOdwwkoRjug"
      },
      "source": [
        "discriminator = Sequential()\n",
        "discriminator.add(Conv2D(64, kernel_size=(5,5), strides=(2,2), padding=’same’, input_shape=(1,28,28), kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "discriminator.add(LeakyRelu(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Conv2D(128, kernel_size=(5,5), strides=(2,2), padding=’same’))\n",
        "discriminator.add(LeakyRelu(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1, activation=’sigmoid’))\n",
        "discriminator.compile(loss=’binary_crossentropy’, optimizer=adam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zIWTtc1Rlsr"
      },
      "source": [
        "###학습 단계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyXhECs3RoNz"
      },
      "source": [
        "ganInput = input(shape=(randomDim,))\n",
        "x = generator(ganInput)\n",
        "ganOutput = discriminator(x)\n",
        "gan = Model(input=ganInput, output=ganOutput)\n",
        "gancompile(loss=’binary_crossentropy’, optimized=adam)\n",
        "\n",
        "dLosses = []\n",
        "gLosses = []\n",
        "def train(epochs=1, batchSize=128):\n",
        "    batchCount = X_train.shape[0] / batchSize\n",
        "    print ‘Epochs:’, epochs\n",
        "print ‘Batch size:’, ebatchSize\n",
        "print ‘Batches per epoch:’, batchCount\n",
        "    for e in xrange(1, epochs+1):\n",
        "        print ‘-‘*15, ‘Epoch %d’ % e, ‘-‘*15\n",
        "        for _ in tqdm(xrange(batchCount)):\n",
        "            noise = np.random.normal(0,1,size=[batchSize, randomDim])\n",
        "            generatedImages = generator.predict(noise)\n",
        "            X = np.concatenate([imageBatch, generatedImages])\n",
        "            yDis = np.zeros(2*batchSize)\n",
        "            yDis[:batchSize] = 0.9\n",
        "            discriminator.trainable = True\n",
        "            dloss = discriminator.train_on_batch(X, yDis)\n",
        "            noise = np.random.norml(0,1,size=[batchSize, randomDim])\n",
        "            yGen = np.ones(batchSize)\n",
        "            discriminator.trainable = False\n",
        "            gloss = gan.train_on_batch(noise, yGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "defriErZRwk_"
      },
      "source": [
        "###이미지 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sP5diB1RzeM"
      },
      "source": [
        "def plotGeneratedImages(epoch, examples=100, dim(10,10), figsize=(10,10)):\n",
        "noise = np.random.normal(0,1,size=[examples, randomDim])\n",
        "generatedImages = generator.predict(noise)\n",
        "\n",
        "plt.figure(figsize=figsize)\n",
        "for I in range(generatedImages, shape[0]):\n",
        "plt.subplot(dim[0], dim[1], i+1)\n",
        "plt.imshow(generatedImages[I,0], interpolation’;nearest’, cmap=’gray_r’)\n",
        "plt.axis(‘off’)\n",
        "plt.tight_layout()\n",
        "plt.savefig(‘images/dcgan_generated_image_epoch_%d.png’ % epoch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}